{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LP videos list on Youku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,openpyxl\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "sheet = wb.active\n",
    "sheet.title = 'AutoGenerated'\n",
    "head_row = ['title','duration','link']\n",
    "sheet.append(head_row)\n",
    "\n",
    "for i in range(1,7):\n",
    "    url = 'http://i.youku.com/i/UMzM3NTc0ODQ=/videos?spm=a2hzp.8253869.0.0&order=1&page='+str(i)+'&last_item=&last_pn=5&last_vid=89392462'\n",
    "    r = requests.get(url)\n",
    "    s = BeautifulSoup(r.text,'html.parser')\n",
    "    info = s.find('div',class_='videos-list')\n",
    "    video_list = info.find_all('div',class_='v-link')\n",
    "    for i in video_list:\n",
    "        hyperlink = 'http:{}'.format(i.a['href'])\n",
    "        title = i.a['title']\n",
    "        try:\n",
    "            v_time = '{}\"'.format(i.find('span').text.replace(':',\"'\"))\n",
    "        except:\n",
    "            v_time = 'locked video'\n",
    "        sheet.append([title,v_time,hyperlink])\n",
    "wb.save('auto generated video lists.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,openpyxl\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "sheet = wb.active\n",
    "sheet.title = 'sales&distributors'\n",
    "head_row = ['name','country','website']\n",
    "sheet.append(head_row)\n",
    "\n",
    "url = 'https://sheffdocfest.com/articles/671-doc-comment-sales-and-distribution-companies/'\n",
    "r = requests.get(url)\n",
    "s = BeautifulSoup(r.text,'html.parser')\n",
    "info = s.find('article').find_all('h6')\n",
    "\n",
    "for h6 in info:\n",
    "    if h6.a!=None:\n",
    "        name = h6.a.text\n",
    "        link = h6.a['href']\n",
    "    else:\n",
    "        country = h6.text\n",
    "         \n",
    "    sheet.append([name,country,link])\n",
    "\n",
    "wb.save('sales & distributor.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,openpyxl\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "sheet = wb.active\n",
    "sheet.title = 'draft'\n",
    "head_row = ['country']\n",
    "sheet.append(head_row)\n",
    "\n",
    "url = 'https://sheffdocfest.com/articles/671-doc-comment-sales-and-distribution-companies/'\n",
    "r = requests.get(url)\n",
    "s = BeautifulSoup(r.text,'html.parser')\n",
    "info = s.find('article').find_all('h6')\n",
    "\n",
    "for h6 in info:\n",
    "    if h6.strong!=None and h6.strong.a==None:\n",
    "        country = h6.strong.text\n",
    "    else:\n",
    "        continue\n",
    "    sheet.append([country])\n",
    "\n",
    "wb.save('draft.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 精挑细选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llist=['https://www.imdb.com/title/tt9351980/']\n",
    "credit_link='companycredits?ref_=ttco_ql_4'\n",
    "award_link='awards?ref_=ttco_ql_op_1'\n",
    "home_link='?ref_=ttloc_ql'\n",
    "numList = [\n",
    "    'https://www.imdb.com/title/tt9351980/','https://www.imdb.com/title/tt0441881/','https://www.imdb.com/title/tt7681902/','https://www.imdb.com/title/tt9358052/',\n",
    "    'https://www.imdb.com/title/tt7905466/','https://www.imdb.com/title/tt5105734/','https://www.imdb.com/title/tt8760684/','https://www.imdb.com/title/tt4935462/',\n",
    "    'https://www.imdb.com/title/tt9352780/','https://www.imdb.com/title/tt8811382/','https://www.imdb.com/title/tt9353436/','https://www.imdb.com/title/tt9358044/',\n",
    "    'https://www.imdb.com/title/tt8923482/','https://www.imdb.com/title/tt8995252/','https://www.imdb.com/title/tt9617456/','https://www.imdb.com/title/tt9351746/',\n",
    "    'https://www.imdb.com/title/tt8793990/','https://www.imdb.com/title/tt8192948/','https://www.imdb.com/title/tt10011226/','https://www.imdb.com/title/tt8106566/',\n",
    "    'https://www.imdb.com/title/tt8991268/','https://www.imdb.com/title/tt9358052/','https://www.imdb.com/title/tt9358204/','https://www.imdb.com/title/tt6893836/',\n",
    "    'https://www.imdb.com/title/tt5895028/','https://www.imdb.com/title/tt6792200/','https://www.imdb.com/title/tt8884430/','https://www.imdb.com/title/tt7664504/',\n",
    "    'https://www.imdb.com/title/tt7286916/','https://www.imdb.com/title/tt9573980/','https://www.imdb.com/title/tt6769208/','https://www.imdb.com/title/tt0914376/',\n",
    "    'https://www.imdb.com/title/tt0429466/','https://www.imdb.com/title/tt6964076/','https://www.imdb.com/title/tt1966604/','https://www.imdb.com/title/tt2545428/',\n",
    "    'https://www.imdb.com/title/tt7476236/','https://www.imdb.com/title/tt4645358/','https://www.imdb.com/title/tt6510332/','https://www.imdb.com/title/tt11444082/',\n",
    "    'https://www.imdb.com/title/tt9358052/','https://www.imdb.com/title/tt7775622/'\n",
    "]\n",
    "\n",
    "import requests,openpyxl\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "sheet = wb.active\n",
    "sheet.title = 'film list'\n",
    "head_row = ['title','release year','distributors','awards']\n",
    "sheet.append(head_row)\n",
    "\n",
    "\n",
    "for num in numList:\n",
    "    url_1 = num+credit_link\n",
    "    r_1 = requests.get(url_1)\n",
    "    s_1 = BeautifulSoup(r_1.text,'html.parser')\n",
    "    \n",
    "    url_2 = num+award_link\n",
    "    r_2 = requests.get(url_2)\n",
    "    s_2 = BeautifulSoup(r_2.text,'html.parser')\n",
    "    awards_info = s_2.find('div',class_='article listo')\n",
    "    \n",
    "#     url_3 = num+home_link\n",
    "#     r_3 = requests.get(url_3)\n",
    "#     s_3 = BeautifulSoup(r_3.text,'html.parser')\n",
    "#     tags = s_3.find('div',id='titleDetails').find_all('h4',class_='inline')\n",
    "#     for i in tags:\n",
    "#         if i.text==\n",
    "    \n",
    "    film_title = s_1.find('h3',itemprop='name')\n",
    "    title = film_title.a.text\n",
    "    year = film_title.span.text.lstrip().rstrip().replace('(','').replace(')','')\n",
    "    check = s_1.find('div',id='company_credits_content').find('h4',id='distributors')\n",
    "    if check!=None:\n",
    "        info_list = s_1.find('div',id='company_credits_content').find_all('ul',class_='simpleList')\n",
    "        try:\n",
    "            film_credit = info_list[1].find_all('li')\n",
    "            distri_list = []\n",
    "            for i in film_credit:\n",
    "                distri = i.text.strip().replace('            ',' ')\n",
    "                distri_list.append(distri)\n",
    "            distributors = '; '.join(distri_list)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        award_list=[]\n",
    "        if awards_info!=None:\n",
    "            awards_list = awards_info.find_all('h3')\n",
    "            for h3 in awards_list:\n",
    "                award_list.append(h3.text.lstrip().rstrip())\n",
    "            awards = ' '.join(award_list[1:])\n",
    "            \n",
    "        else:\n",
    "            awards = 'null'\n",
    "    else:\n",
    "        continue   \n",
    "    \n",
    "    sheet.append([title,year,distributors,awards])\n",
    "\n",
    "\n",
    "wb.save('film_list.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,openpyxl\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "sheet = wb.active\n",
    "sheet.title = 'company list'\n",
    "head_row = ['company','website']\n",
    "sheet.append(head_row)\n",
    "\n",
    "url = 'https://www.documentary.org/feature/guide-documentary-distributors'\n",
    "r = requests.get(url)\n",
    "s = BeautifulSoup(r.text,'html.parser')\n",
    "\n",
    "info = s.find('div',class_='field field-name-body field-type-text-with-summary field-label-hidden field-delta-0').find_all('p')\n",
    "info_list = info[13:128]\n",
    "\n",
    "for i in info_list: \n",
    "    name = i.strong.text\n",
    "    try:\n",
    "        website = i.a['href']\n",
    "    except:\n",
    "        website = 'null'\n",
    "    sheet.append([name,website])\n",
    "    \n",
    "wb.save('distributor companys.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### openpyxl 练习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Filmoption International (2019) (World-wide) (all media) ',\n",
       " 'Indie Rights (2020) (USA) (all media)']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('/Users/mac/Desktop/Documentaries List(1).xlsx',sheet_name='Sheet1')\n",
    "outerList = data['发行方Distributor'].to_list()\n",
    "for i in outerList:\n",
    "    info = i.split('\\n')\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "sheet = wb.active\n",
    "sheet.title = 'text'\n",
    "sheet['B5'] = '234\\nrrr'\n",
    "rows = [['list test'],[1,34,4],['a','b']]\n",
    "for i in rows:\n",
    "    sheet.append(i)\n",
    "wb.save('new test.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = openpyxl.load_workbook('Quotation-Apple video production 20190711.xlsx')\n",
    "sheet = wb.active\n",
    "sheetname = wb.sheetnames\n",
    "sheet['C12'].value\n",
    "# wb.save('Quotation-Apple video production 20190711.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,openpyxl\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "sheet = wb.active\n",
    "sheet.title = 'test'\n",
    "sheet.append(['title','album','time','link'])\n",
    "\n",
    "url = 'https://c.y.qq.com/soso/fcgi-bin/client_search_cp'\n",
    "for x in range(3):\n",
    "\n",
    "    params = {\n",
    "        'ct': '24',\n",
    "        'qqmusic_ver': '1298',\n",
    "        'new_json': '1',\n",
    "        'remoteplace': 'sizer.yqq.song_next',\n",
    "        'searchid': '64405487069162918',\n",
    "        't': '0',\n",
    "        'aggr': '1',\n",
    "        'cr': '1',\n",
    "        'catZhida': '1',\n",
    "        'lossless': '0',\n",
    "        'flag_qc': '0',\n",
    "        'p': str(x + 1),\n",
    "        'n': '20',\n",
    "        'w': '滨崎步',\n",
    "        'g_tk': '5381',\n",
    "        'loginUin': '0',\n",
    "        'hostUin': '0',\n",
    "        'format': 'json',\n",
    "        'inCharset': 'utf8',\n",
    "        'outCharset': 'utf-8',\n",
    "        'notice': '0',\n",
    "        'platform': 'yqq.json',\n",
    "        'needNewCode': '0'\n",
    "    }\n",
    "\n",
    "    res_music = requests.get(url, params=params)\n",
    "    json_music = res_music.json()\n",
    "    list_music = json_music['data']['song']['list']\n",
    "    for music in list_music:\n",
    "        name = music['name']\n",
    "        album = music['album']['name']\n",
    "        time = str(music['interval']) + '秒'\n",
    "        link = 'https://y.qq.com/n/yqq/song/' + music['file']['media_mid'] + '.html\\n\\n'\n",
    "        sheet.append([name,album,time,link])\n",
    "        \n",
    "wb.save('song list.xlsx')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = openpyxl.load_workbook('song list.xlsx')\n",
    "s = w.active\n",
    "for i in range(10,62):\n",
    "    cell = s['C'+str(i)].value\n",
    "    sec = int(cell[:-1])\n",
    "    time = '{}m {}s'.format(sec//60,sec%60)\n",
    "    s['C'+str(i)].value = time\n",
    "    \n",
    "# w.save('song list.xlsx')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 抓知乎大v发表的文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,openpyxl\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "sheet = wb.active\n",
    "sheet.title = 'titles'\n",
    "\n",
    "url='https://www.zhihu.com/api/v4/members/zhang-jia-wei/articles?'\n",
    "headers={'user-agent':\n",
    "           'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36'\n",
    "        }\n",
    "offset=10\n",
    "for i in range(53):\n",
    "    params={\n",
    "        'include':\n",
    "        'data[*].comment_count,suggest_edit,is_normal,thumbnail_extra_info,thumbnail,can_comment,comment_permission,admin_closed_comment,content,voteup_count,created,updated,upvoted_followees,voting,review_info,is_labeled,label_info;data[*].author.badge[?(type=best_answerer)].topics',\n",
    "        'offset':str(offset),\n",
    "        'limit':'10',\n",
    "        'sort_by':'voteups'\n",
    "    }\n",
    "    res = requests.get(url,headers=headers,params=params)\n",
    "    article_json = res.json()\n",
    "    data = article_json['data'] #a list\n",
    "    for i in data:\n",
    "        sheet.append([i['title']])\n",
    "        if i==None:\n",
    "            sheet.append([offset])\n",
    "            \n",
    "    offset+=20\n",
    "    \n",
    "    if article_json['paging']['is_end']==True:\n",
    "        break\n",
    "\n",
    "wb.save('articles.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csv练习 小区楼房信息表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_file = open('demo.csv','r',newline='')\n",
    "reader=csv.reader(csv_file)\n",
    "for row in reader:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('assets.csv', 'w', newline='') as csvfile:\n",
    "#调用open()函数打开csv文件，传入参数：文件名“assets.csv”、追加模式“a”、newline=''。\n",
    "    writer = csv.writer(csvfile, dialect='excel')\n",
    "    # 用csv.writer()函数创建一个writer对象。\n",
    "    header=['小区名称', '地址', '建筑年份', '楼栋', '单元', '户室', '朝向', '面积']\n",
    "    writer.writerow(header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=input('请输入小区名称：')\n",
    "address = input('请输入小区地址：')\n",
    "year = input('请输入小区建造年份：')\n",
    "block = input('请输入楼栋号：')\n",
    "unit=input('请输入单元号：')\n",
    "\n",
    "start_floor = input('请输入起始楼层：')\n",
    "end_floor = input('请输入终止楼层：')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始输入模板数据\n",
    "input('接下来请输入起始层每个房间的门牌号、南北朝向及面积，按任意键继续')\n",
    "\n",
    "start_floor_rooms = {}\n",
    "floor_last_number = []\n",
    "# 收集起始层的房间信息\n",
    "\n",
    "# 定义循环控制量\n",
    "room_loop = True\n",
    "while room_loop:\n",
    "    last_number = input('请输入起始楼层户室的尾号:（如01，02）')\n",
    "    floor_last_number.append(last_number)\n",
    "    #将尾号用append()添加列表里，如floor_last_number = ['01','02']\n",
    "    room_number = int(start_floor + last_number)\n",
    "    #户室号为room_number,由楼层start_floor和尾号last_number组成,如301\n",
    "\n",
    "    direction = int(input('请输入 %d 的朝向(南北朝向输入1，东西朝向输入2)：' % room_number ))\n",
    "    area = int(input('请输入 %d 的面积，单位 ㎡ ：' % room_number))\n",
    "    start_floor_rooms[room_number] = [direction,area]\n",
    "    # 户室号为键，朝向和面积组成的列表为值，添加到字典里，如start_floor_rooms = {301:[1,70]}\n",
    "\n",
    "    continued= input('是否需要输入下一个尾号？按 n 停止输入，按其他任意键继续：')\n",
    "    #加入打破循环的条件\n",
    "    if continued == 'n':\n",
    "        room_loop = False\n",
    "    else:\n",
    "        room_loop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_rooms = {}    #新建一个放单元所有户室数据的字典\n",
    "        \n",
    "unit_rooms[start_floor] = start_floor_rooms          #unit_rooms={3:{301:[1,80],302:[1,80],303:[2,90],304:[2,90]}}\n",
    "for floor in range(int(start_floor) + 1, int(end_floor) + 1):  #遍历除初始楼层外的其他楼层\n",
    "        floor_rooms = {}\n",
    "        for i in range(len(start_floor_rooms)):  #遍历每层有多少个房间，这里是3，即执行for i in range 3 的循环\n",
    "            number = str(floor) + floor_last_number[i]\n",
    "            info = start_floor_rooms[int(start_floor + floor_last_number[i])]\n",
    "            # 依次取出字典start_floor_rooms键对应的值，即面积和朝向组成的列表\n",
    "            floor_rooms[int(number)] = info\n",
    "            #给字典floor_rooms添加键值对，floor_rooms = {401:[1,80]}\n",
    "        unit_rooms[floor] = floor_rooms\n",
    "        \n",
    "print(unit_rooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('assets.csv', 'a', newline='')as csvfile:\n",
    "    writer = csv.writer(csvfile, dialect='excel')\n",
    "    for sub_dict in unit_rooms.values():\n",
    "        for room,info in sub_dict.items():\n",
    "            dire = ['', '南北', '东西']\n",
    "            writer.writerow([title,address,year,block,unit,room,dire[info[0]],info[1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
